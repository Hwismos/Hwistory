<p data-ke-size="size16">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</p>
<p data-ke-size="size16">METRIC-GCL: <b><span style="color: #ee2323;">m</span></b>ulti vi<b><span style="color: #ee2323;">e</span></b>w and asymme<b><span style="color: #ee2323;">tric</span></b> <span style="color: #ee2323;"><b>g</b></span>raph <span style="color: #ee2323;"><b>c</b></span>ontrastive <span style="color: #ee2323;"><b>l</b></span>earning</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size18"><b>가설</b></p>
<p data-ke-size="size16"><i>[24.03.15]</i></p>
<p data-ke-size="size16">&bull; aggregation 디코더를 이용하는 MUSE의 1-hop context learning 프로세스를 GACL의 reconstruction 디코더로 대체함으로써 2-hop semantic 정보를 추가로 학습할 수 있음</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size18"><b>대조 학습</b></p>
<p data-ke-size="size16"><i>[24.03.18]</i></p>
<p data-ke-size="size16">&bull; 정점 \(v_i\)의 대조 손실: \( -\log \frac{\exp{\mathsf{sim} (z_{i}, z_{j}) / \tau }} {\sum_{v_k \in \mathcal{V \setminus v_i} } \exp{\mathsf{sim} (z_{i}, z_{k}) / \tau }} \). \(z_i\)는 정점 \(v_i\)의 표현. \(v_j\)와 \(v_k\)는 각각 \(v_i\)의 양성 샘플과 음성 샘플. 분모에서는 음성 샘플과의 유사도 뿐 아니라 양성 샘플과의 유사도 함께 고려함</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><i>[24.03.21]</i></p>
<p data-ke-size="size16">&bull; 대조 학습의 핵심은 비슷해지고 달라지도록 하는 대상</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size18"><b>모델별 핵심 훈련 원리</b></p>
<p data-ke-size="size16"><b>MUSE의 훈련 원리</b></p>
<p data-ke-size="size16"><i>[24.03.19]</i></p>
<p data-ke-size="size16">&bull; 4개의 데이터(\( X_{\mathsf{original}}, \ \ X_{\mathsf{dropped}}, \ \ A_{\mathsf{diagonal}}, \ \ A_{\mathsf{original}}, \ \ A_{\mathsf{dropped}} \))와 차수 데이터( \( d_{v} \) )를 이용하여 모델을 훈련시킴</p>
<p data-ke-size="size16">&bull; 옵티마이저는 (1) GCN 모델 레이어(<span style="color: #ee2323;">fcs[0, 1]</span>), (2) MLP 모델 레이어(<span style="color: #ee2323;">gate[0, 1, 2]</span>), (3) 프로젝션 레이어(<span style="color: #ee2323;">fcs[2, 3, 4]</span>)의 파라미터들을 갱신하며 (1)/(3)과 (2)의 학습률을 구분함</p>
<p data-ke-size="size16">&bull; \( \mathcal{L}_{contrast} \)(loss_gnn)를 이용한 파라미터 갱신과 \( \mathcal{L}_{\phi} \)(mlp_loss)를 이용한 파라미터 갱신을 순차적으로 수행함</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><b>GACL의 훈련 원리</b></p>
<p data-ke-size="size16"><i>[24.03.19]</i></p>
<p data-ke-size="size16">&bull; 원본의 특징 데이터( \( X_{\mathsf{original}} \) )와 관계 데이터( \( A_{\mathsf{original}} \) )를 이용하여 모델을 훈련시키며, v_emb와 projected_emb 간의 상호정보량을 최대로 하는 방향으로 <span style="color: #ee2323;">graphconv[1, 2]</span> 레이어와 <span style="color: #ee2323;">projector</span> 레이어의 파라미터들을 갱신함</p>
<p data-ke-size="size16">&bull; v_emb와 projected_emb 간의 대조 학습을 위한 샘플링에는 v_emb와 u_emb를 이용하며, u_emb를 생성하는 <span style="color: #ee2323;">target_graphconv[1, 2]</span> 레이어의 파라미터는 <span style="color: #ee2323;">graphconv[1, 2]</span> 레이어의 파라미터에 의존하여 갱신됨</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size18"><b>파이토치의 모델 훈련 원리</b></p>
<p data-ke-size="size16"><i>[24.03.19]</i></p>
<p data-ke-size="size16">&bull; 모델은 학습 파라미터들을 갖는 레이어들의 집합. 훈련 시킬 모델(\( h_{\alpha} \))은 train 모드로 설정하고 훈련시키지 않을 모델(\( h_{\beta} \))은 eval 모드로 설정</p>
<p data-ke-size="size16">&bull; 옵티마이저는 기울기(gradient)를 트래킹할 수 있는 \( h_{\alpha} \)의 파라미터들을 손실에 기반하여 갱신함</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size18"><b>실험 방법</b></p>
<p data-ke-size="size16"><i>[24.03.19]</i></p>
<p>[##_Image|kage@c0ID3p/btsFUqxYSpj/1Z4ZB08x5lHUYnUcWsFfKk/img.png|CDM|1.3|{"originWidth":1049,"originHeight":696,"style":"alignCenter"}_##][##_Image|kage@ttaXr/btsFWJJNRcb/NNRn9R57yir2XCUTOKwmo0/img.png|CDM|1.3|{"originWidth":1182,"originHeight":806,"style":"alignCenter"}_##]</p>
<p data-ke-size="size16">&bull; MUSE에만 있는 gate[1, 2, 3] 레이어는 파라미터 갱신을 규제(MLP Loss)하는 역할을 함. GACL의 학습 수준을 신뢰할 수 있다고 가정하고 MUSE의 semantic-view based 대조 학습 프로세스만을 GACL에 추가하고자 함. 이를 위해 \(X_{\mathsf{dropped}}\)와 \(A_{\mathsf{identity}}\) 데이터를 생성하고 \(h_{1}\)과 \(h_{2}\)를 생성하는 별도의 projector를 추가로 삽입하여 두 표현 간 대조 손실을 계산, GACL의 \( \mathcal{L}_{A}\) 손실과 가중합. GACL의 결과 원복 여부를 먼저 확인하는 것이 중요</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size18"><b>실험 결과</b></p>
<p data-ke-size="size16"><i>[24.03.20]</i></p>
<p data-ke-size="size16">&bull; GACL은 정상적으로 복원됨을 확인함 . 본문은 HT 데이터셋 9개와 HM 데이터셋 6개를 사용. 검증에는 HT 데이터셋 6개, HM 데이터셋 4개를 사용</p>
<table style="border-collapse: collapse; width: 100%;" border="1" data-ke-align="alignLeft" data-ke-style="style12">
<tbody>
<tr>
<td style="width: 20.0775%; text-align: center;">데이터셋 (<span style="color: #ee2323;">HT</span>/<span style="color: #006dd7;">HM</span>)</td>
<td style="width: 46.5891%; text-align: center;">정점 분류 정확도 (관측 결과/논문 결과)</td>
<td style="width: 33.3333%; text-align: center;">걸린 시간</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #ee2323;">Texas</span></td>
<td style="width: 46.5891%; text-align: center;"><b>71.62</b> / 71.08&nbsp;</td>
<td style="width: 33.3333%; text-align: center;">06:12</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #ee2323;">Cornell</span></td>
<td style="width: 46.5891%; text-align: center;"><b>60.54</b> / 59.33</td>
<td style="width: 33.3333%; text-align: center;">07:02</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #ee2323;">Wisconsin</span></td>
<td style="width: 46.5891%; text-align: center;"><b>70.20</b> / 69.22</td>
<td style="width: 33.3333%; text-align: center;">08:13</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #ee2323;">Chameleon</span></td>
<td style="width: 46.5891%; text-align: center;"><b>69.17 </b>/ 69.12</td>
<td style="width: 33.3333%; text-align: center;">52:19</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #ee2323;">Actor(Film)</span></td>
<td style="width: 46.5891%; text-align: center;">29.93 / <b>30.03</b></td>
<td style="width: 33.3333%; text-align: center;">04:12:01</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #ee2323;">Crocordile</span></td>
<td style="width: 46.5891%; text-align: center;">66.15 / <b>66.17</b></td>
<td style="width: 33.3333%; text-align: center;">06:35:16</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #006dd7;">Cora</span></td>
<td style="width: 46.5891%; text-align: center;"><b>84.40</b> / 84.20</td>
<td style="width: 33.3333%; text-align: center;">00:08</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #006dd7;">Citeseer</span></td>
<td style="width: 46.5891%; text-align: center;"><b>74.20</b> / 73.63</td>
<td style="width: 33.3333%; text-align: center;">00:05</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #006dd7;">Pubmed</span></td>
<td style="width: 46.5891%; text-align: center;"><b>85.10</b> / 82.02</td>
<td style="width: 33.3333%; text-align: center;">00:26</td>
</tr>
<tr>
<td style="width: 20.0775%; text-align: left;"><span style="color: #006dd7;">Photo</span></td>
<td style="width: 46.5891%; text-align: center;">92.83 / <b>93.31</b></td>
<td style="width: 33.3333%; text-align: center;">00:15</td>
</tr>
</tbody>
</table>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16">&bull; semantic 대조 학습을 수행하는 projection 레이어 삽입. Texas와 Cornell에 대한 결과를 확인하였을 때 성능상 차이가 거의 없음. 차이가 별로 없는 이유를 탐구해야 함. semantic 대조 손실을 0.6으로 감쇄시킨 뒤 GACL 손실과 합하긴 하였지만 그럼에도 성능상 차이가 미미함. 구현 상 문제가 없는지도 한 번 더 검토해야 함</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><i>[24.03.21]</i></p>
<p data-ke-size="size16">&bull; 개인 slurm 클러스터 세팅. GACL Loss는 \(|\mathcal{V}|\)와 \(|\mathcal{N}(v)|\)로 정규화하고, MUSE Loss는 \(2|N| = 2|\mathcal{V}|\)로 정규화함</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />