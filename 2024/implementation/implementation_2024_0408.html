<p data-ke-size="size16">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</p>
<style>
  code {
    font-family: MyFancyCustomFont, monospace;
    font-size: inherit;
    background: #ffeff0;
    word-wrap: break-word;
    box-decoration-break: clone;
    padding: 0.1rem 0.3rem 0.2rem;
    border-radius: 0.2rem;
  }
</style>

<!-- 메인 -->
<p data-ke-size="size18"><b>Heterophilous Graph 데이터에 대한 심층학습 성능 향상을 위한 여섯 편의 논문 비교 분석 (1)</b></p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<!-- 처음 -->
<p data-ke-size="size16">문서 단위의 관계 추출 문제를 다루는 모델인 Sag-DRE의 설계가 어떤 번역을 거쳐 구현되었는지를 분석하고자 한다.</p>
<p data-ke-size="size16">&nbsp;</p>

<!-- 처음과 중간의 여백 -->
<p data-ke-size="size16">&nbsp;</p>

<!-- 중간 -->
<p data-ke-size="size16">논리를 번역하기에 앞서 핵심적인 데이터 형태에 대한 이해가 필요. 메타 데이터에 관계(relation), 단어(word),</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16">모델의 레이어 구성. 엔티티의 타입과 아이디에 대한 임베딩 행렬이 각각 존재.</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16">핵심 번역 3.</p>
<p data-ke-size="size16">&nbsp;</p>

<!-- 중간과 끝의 여백 -->
<p data-ke-size="size16">&nbsp;</p>

<!-- 끝 -->
<p data-ke-size="size16">끝</p>

<p>
  [##_Image|kage@BNrew/btsGtWihCD9/KRlN5K9gby2B0KQnnHFiK0/img.png|CDM|1.3|
  {"originWidth":1022,"originHeight":711,"style":"alignCenter","caption":"그림 1"}_##]
</p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size16">&bull; 1,000자</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<!-- 서브 -->
<p data-ke-size="size16"><i>[24.04.06]</i></p>
<p data-ke-size="size16">
  &bull; [<b>ALT</b>] <code>augmenter</code>를 이용해 \(\mathbf{W}\)를 <code>edge_weight</code>에 할당하고 PyG의 데이터셋 객체인 <code>data</code>를
  <code>model</code>에 전달
</p>
<p data-ke-size="size16">&bull; [<b>DGCN</b>] \(\mathbf{H}\)와 \(\mathbf{S}\)를 생성하는 각각의 스크립트를 임포트하여 사용</p>
<p data-ke-size="size16">
  &bull; [<b>GACL</b>] <code>forward_encoder</code> 메소드로 \(\mathbf{v}\), \(\mathbf{u}\) 그리고 \(\mathbf{p}\) 모두 생성. 이웃한 정점들의
  \(\mathbf{u}\) 벡터들을 양성 샘플로 취급하고 본인을 포함한 모든 정점들의 \(\mathbf{v}\) 벡터를 음성 샘플로 취급하여
  <code>sampled_embedding_list</code>와 <code>sampled_embedding_neg_list</code> 생성. 대조학습을 통해 \(\mathbf{u}\)의 신호를 \(\mathbf{p}\)가 예측할
  수 있도록 레이어 갱신
</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size16"><b>피드백</b></p>
<p data-ke-size="size16">
  &bull; 핵심 논리/수식에 대한 번역보다 데이터 전처리 등의 준비 단계에 대한 번역이 더 복잡하며 이 부분에 대한 핵심 알고리즘을 포착하지 못함
</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
