<p data-ke-size="size16">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</p>
<p data-ke-size="size18">
  <b>1. Contrastive Meta-Learning for Few-Shot Node Classification</b>
</p>
<p data-ke-size="size16"><i>[24.03.11]</i></p>
<p data-ke-size="size16">
  &bull; intra-class와 inter-class를 고려한 정점의 표현 생성. 코드 있음
</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><i>[24.03.24]</i></p>
<p data-ke-size="size16">
  &bull; 퓨샷 정점 분류를 위해 정점들의 클래스 집합 \(\mathcal{C}\)를 충분한
  정답 값을 갖고 있는 \(\mathcal{C}_{tr}\)과 부족한 정답 값을 갖고 있는
  \(\mathcal{C}_{te}\)로 분리 (\(\mathcal{C}_{tr} \cap \mathcal{C}_{te} =
  \emptyset\)). \(\mathcal{C}_{tr}\)로 훈련한 모델은 하위 작업(\(\mathcal{T} =
  \{S, Q\} \ \ \mathsf{from} \ \ \mathcal{C}_{te}\))을 수행. \(S\)와 \(Q\)가
  \(N\)개의 클래스로 구성되고 \(S\)는 각 클래스에 대해 정답 값이 있는 \(K\)개의
  정점을 가질 때, 이를 N-way K-shot 문제로 칭함. 메타 태스크(meta-task)는
  \(T\)번의 태스크( \( \mathcal{T}_{t} = \{ S_{t}, Q_{t} \} \) )를 각각의
  \(\mathcal{C}_{tr}\)와 \(\mathcal{C}_{te}\) 집합에서 수행함으로써 식 (1-1)과
  같이 인코더의 파라미터를 갱신함. contrastive meta-learning loss
  \(\mathcal{L}_{MC}\)는 식 (1-2)의 관계를 가짐. 이때 \(v_{i}^{j}\)는 클래스
  \(i\)에 속하는 정점 \(j\)
</p>
<p data-ke-size="size16">
  $$ \left\{ \begin{array}{rcl} \tilde{\theta}^{(t)} \leftarrow
  -\mathcal{L}_{MC} (S_{t}; \theta^{(t)}) \\ \theta^{(t+1)} \leftarrow
  -\mathcal{L}_{CE} (Q_{t}; \tilde{\theta}^{(t)}) \tag{1-1} \end{array}\right.
  $$
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathcal{L}_{MC} \varpropto \mathcal{L}_{i, j} \varpropto
  -\log \frac{\mathsf{MI} (v^{j}_{i}, C_{i})}{\sum_{k=1, k \neq i}^{N}
  \mathsf{MI} (v^{j}_{i}, C_{k})} \tag{1-2} \end{equation} $$
</p>
<p data-ke-size="size16">
  &bull; \(S_{i, j}\)는 \(v_{i}\)와 \(v_{j}\) 사이의 중요도 점수. \(\Gamma
  (v_{i})\)는 \(v_{i}\)와 이웃하며 임계치 이상의 \(S_{i, j}\)를 갖는
  정점들(\(v_{j}\))로 구성됨. 클래스 \(i\)에 속한 정점 \(j\)에 대한 표현은
  centroid(식 (2-1))와 mean(식 (2-2)) 함수를 이용하여 생성함
</p>
<p data-ke-size="size16">
  $$ \begin{equation} f_{1}(v_{i}^{j})= F_{1}(\mathbf{H}_{i}^{j}) =
  F_{1}(\mathsf{GNN}_{\theta} (\mathcal{V}_{i}^{j}, \mathcal{E}_{i}^{j},
  \mathbf{X}_{i}^{j})) \tag{2-1} \end{equation} $$
</p>
<p data-ke-size="size16">
  $$ \begin{equation} f_{2}(v_{i}^{j})= F_{2}(\mathbf{H}_{i}^{j}) =
  F_{2}(\mathsf{GNN}_{\theta} (\mathcal{V}_{i}^{j}, \mathcal{E}_{i}^{j},
  \mathbf{X}_{i}^{j})) \tag{2-2} \end{equation} $$
</p>
<hr
  contenteditable="false"
  data-ke-type="horizontalRule"
  data-ke-style="style5"
/>
<p data-ke-size="size18">
  <b>2. Neighbor Contrastive Learning on Learnable Graph Augmentation</b>
</p>
<p data-ke-size="size16"><i>[24.03.25]</i></p>
<p data-ke-size="size16">
  &bull; 코드 있음. InfoNCE와 NT-Xent는 모두 다른 뷰(표현 행렬)에 있는 본인
  정점만을 양성 샘플로 취급. InfoNCE는 다른 뷰에 있는 본인이 아닌 모든 정점을
  음성 샘플로 취급. NT-Xent는 다른 뷰 뿐 아니라 같은 뷰 상의 본인 정점이 아닌
  모든 정점을 음성 샘플로 취급
</p>
<p data-ke-size="size16">
  &bull; 가중치 벡터 \(\varphi ^{(k)}\)를 이용하여 \(k\)번째 증강된 인접 행렬을
  생성. \(k\)개의 증강된 그래프로부터 생성한 \(k\)개의 표현을 연결(concat)하여
  정점의 최종 표현 벡터 \(\mathbf{h}_{i}\)를 생성. 증강된 그래프가 두 개라고
  가정할 때 식 (1)과 같이 본인 정점 뿐 아니라 같은 뷰와 다른 뷰에 있는 이웃한
  정점들도 양성 샘플로 취급. 본인이 아니고 이웃하지 않은 정점들을 음성 샘플로
  취급. 뷰 간 대칭성을 위해 \(\sum \ell (\mathbf{h}_{i}^{\mathsf{view}_k})\)를
  정규화하여 최종 손실을 계산
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \ell (\mathbf{h}_{i}^{\mathsf{view}_1}) \varpropto - \log
  [ \mathsf{sim} (\mathbf{h}_{i}^{\mathsf{view}_1},
  \mathbf{h}_{i}^{\mathsf{view}_2}) + \mathsf{sim} (\sum_{v_{j} \in
  \mathcal{N}_{i}} (\mathbf{h}_{i}^{\mathsf{view}_1},
  \mathbf{h}_{j}^{\mathsf{view}_1} + \mathbf{h}_{i}^{\mathsf{view}_1},
  \mathbf{h}_{j}^{\mathsf{view}_2}) )] \tag{1} \end{equation} $$
</p>
<hr
  contenteditable="false"
  data-ke-type="horizontalRule"
  data-ke-style="style5"
/>

<p data-ke-size="size18">
  <b>3. Cluster-guided Contrastive Graph Clustering Network</b>
</p>
<p data-ke-size="size16"><i>[24.03.11]</i></p>
<p data-ke-size="size16">
  &bull; 파라미터를 공유하지 않는 두 인코딩의 결과로부터 클러스터링을 수행하고,
  confidence score를 계산하여 high confidence 노드간의 거리는 줄이고 클러스터
  사이의 거리는 늘리는 방향으로 파라미터들을 조정함. 코드 있음
</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><i>[24.03.24]</i></p>
<p data-ke-size="size16">
  &bull; 파라미터를 공유하지 않는 두 인코더를 통해 식 (1)과 같은 두 개의 표현
  행렬을 생성. 식 (2)를 통해 생성한 결합 표현 행렬에 K-means 알고리즘을 적용하여
  정점 \(v\)에 대한 신뢰(confidence) 점수(\(\mathbf{CONF}_{v}\))를 계산. 각 표현
  행렬로부터 식 (3)과 같이 \(h\)개의 상위 신뢰 점수 인덱싱을 적용하여 일부 표현
  추출. 두 개의 상위 신뢰 표현 행렬을 K개의 군집(\(
  \mathbf{B}_{p}^{\mathsf{view}_1}, \mathbf{B}_{q}^{\mathsf{view}_2} \))으로
  분류(\(p, \ \ q = 1, 2, \dots , K\)). 식 (5)와 같이 각 클러스터별 중심 표현
  벡터를 계산
</p>
<p data-ke-size="size16">
  &bull; 손실은 \(\mathcal{L} = \mathcal{L}_{pos} + \alpha \mathcal{L}_{neg}\)로
  계산. \(\mathcal{L}_{pos}\)는 각각의 인코더로부터 생성된 각각의 클러스터
  상에서 동일한 클러스터에 속하는 상위 표현 벡터들이 유사해지도록 강제함.
  \(\mathcal{L}_{neg}\)는 각각의 인코더로부터 생성되어 각각의 클러스터의 중심
  표현 벡터들이 멀어지도록 강제함
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathbf{E}^{\mathsf{view}_{1}}, \ \
  \mathbf{E}^{\mathsf{view}_{2}} \tag{1} \end{equation} $$
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathbf{E} = \frac{1}{2}(\mathbf{E}^{\mathsf{view}_{1}} +
  \mathbf{E}^{\mathsf{view}_{2}}) \tag{2} \end{equation} $$
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathbf{H}^{\mathsf{view}_{1}} =
  \mathbf{E}^{\mathsf{view}_{1}}_{[h, :]}, \ \ \mathbf{H}^{\mathsf{view}_{2}} =
  \mathbf{E}^{\mathsf{view}_{2}}_{[h, :]} \ \ (\mathbf{H}^{\mathsf{view}} \in
  \mathbb{R}^{h \times \mathsf{emb \ \ size}}) \tag{3} \end{equation} $$
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathbf{B}^{\mathsf{view}_{1}}_{p}, \ \
  \mathbf{B}^{\mathsf{view}_{2}}_{q} \ \ (\mathbf{B} \in \mathbb{R}^{n_{k}
  \times \mathsf{emb \ \ size}}) \tag{4} \end{equation} $$
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathbf{CEN}_{p}^{\mathsf{view}_1} = \mathsf{avg}
  (\mathbf{B}_{p}^{\mathsf{view}_{1}}), \ \ \mathbf{CEN}_{q}^{\mathsf{view}_2} =
  \mathsf{avg} (\mathbf{B}_{q}^{\mathsf{view}_{2}}) \ \ (\mathbf{CEN} \in
  \mathbb{R}^{\mathsf{emb \ \ size}}) \tag{5} \end{equation} $$
</p>

<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><i>[24.03.26]</i></p>
<p data-ke-size="size16">
  &bull; 손실 함수를 식 (6), (7)과 같이 설계. \(p\)와 \(q\)는 각 클러스터의
  인덱스. 식 (4)의 \(n_{k}\)는 클러스터 \(k\)에 속하며 상위 신뢰 점수를 갖는
  정점의 개수
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathcal{L}_{pos} \varpropto - \mathsf{sim}
  (\mathbf{B}_{p[i, :]}^{v_{1}}, \mathbf{B}_{p[i, :]}^{v_{2}} ) \tag{6}
  \end{equation} $$
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathcal{L}_{pos} \varpropto \mathsf{sim}
  (\mathbf{CEN}_{p}^{v_{1}}, \mathbf{CEN}_{q}^{v_{2}}) \tag{7} \end{equation} $$
</p>

<hr
  contenteditable="false"
  data-ke-type="horizontalRule"
  data-ke-style="style5"
/>
<p data-ke-size="size18">
  <b
    >4. Eliciting Structural and Semantic Global Knowledge in Unsupervised Graph
    Contrastive Learning</b
  >
</p>
<p data-ke-size="size16"><i>[24.03.25]</i></p>
<p data-ke-size="size16">
  &bull; InforNCE 함수를 이용. 식 (1)을 통해 \( \mathcal{L}_{str}\) 계산. \(
  \mathbf{U}^{(\ell)} = g_{\psi} (\mathbf{H}^{(\ell)}) = g_{\psi} (\mathsf{ReLU}
  (\tilde{A}_{sym}^{(\ell)} X \Theta) ) \). \(\mathbf{H}^{(1)}\)은 local view.
  식 (1)의 손실은 \(v_{i}\)에 대하여 1-hop에서의 표현과 \(N\)-1개의
  \(\ell\)-hop에서의 표현이 유사해지도록 강제함
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathcal{L}_{str} \varpropto - \log \mathsf{sim} (
  \mathbf{u}_{i}^{(1)}, \mathbf{u}_{i}^{(\ell)} ) \tag{1} \end{equation} $$
</p>
<p data-ke-size="size16">
  &bull; 우도를 최대화하는 방향으로 식 (2)와 같이 \(\mathcal{L}_{sem}\) 계산.
  \(\mathbf{c}_{k} \in \mathbb{R}^{D}\)는 정점의 표현을 바탕으로 계산한 클러스터
  프로토타입 표현 벡터. \(h_{i}\)와 해당 정점의 클러스터 프로토타입 표현 벡터
  \(\mathbf{c}_{z_{i}}\)가 비슷해지도록 강제함
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathcal{L}_{sem} \varpropto - P ( \mathbf{h}_i, z_{i} |
  \theta, \mathbf{C} ) \varpropto - P( z_{i} | \mathbf{h}_{i}, \theta,
  \mathbf{C} ) \varpropto - \frac{ \mathbf{h}_{i} \cdot \mathbf{c}_{z_{i}} }{
  \sum_{k=1}^{K} \mathbf{h}_{i} \cdot \mathbf{c}_{k} } \tag{2} \end{equation} $$
</p>
<hr
  contenteditable="false"
  data-ke-type="horizontalRule"
  data-ke-style="style5"
/>
<p data-ke-size="size18">
  <b>5. Hard Sample Aware Network for Contrastive Deep Graph Clustering</b>
</p>
<p data-ke-size="size16"><i>[24.03.11]</i></p>
<p data-ke-size="size16">
  &bull; 그래프 클러스터링과 그래프 대조 학습. hard positive/negative samples.
  코드 있음
</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><i>[24.03.25]</i></p>
<p data-ke-size="size16">
  &bull; 한 정점에 대한 하드 샘플은 낮은 유사도를 갖는 양성 샘플과 높은 유사도를
  갖는 음성 샘플. \(i\)-sample은 정점 \(i\)를 의미. 2개의 attribute 인코더와
  2개의 structure encoder를 이용하여 총 4개의 서로 다른 뷰(표현 행렬)를 생성.
  attribute-structure 유사도 함수 \(S(i^{\mathsf{view}_{j}},
  k^{\mathsf{view}_{\ell}})\)를 식 (1)과 같이 정의. \(\mathbf{Z}\)와
  \(\mathbf{E}\)는 각각 attribute 표현 행렬과 structure 표현 행렬
</p>
<p data-ke-size="size16">
  $$ \begin{equation} S(i^{\mathsf{view}_{j}}, k^{\mathsf{view}_{\ell}}) =
  \alpha \cdot ( \mathbf{Z}_{i}^{\mathsf{view}_j} )^T \cdot
  \mathbf{Z}_{k}^{\mathsf{view}_\ell} + (1 - \alpha) \cdot (
  \mathbf{E}_{i}^{\mathsf{view}_j} )^T \cdot \mathbf{E}_{k}^{\mathsf{view}_\ell}
  \tag{1} \end{equation} $$
</p>
<p data-ke-size="size16">
  &bull; \(\mathbf{P} \in \mathbb{R}^{N}\)는 정점별 슈도 레이블 벡터.
  \(\mathbf{H} \in \mathbb{R}^{M}\)는 \(M\)개의 높은 신뢰도를 갖는 슈도 레이블
  벡터. \(\mathbf{Q} \in \mathbb{R}^{N \times N}\)의 원소는 샘플 \(i\)와 \(j\)의
  슈도 레이블이 갖다면 1, 아니면 0. 가중치 조정 함수
  \(\mathcal{M}(i^{\mathsf{view}_{j}}, k^{\mathsf{view}_{\ell}})\)을 식 (2)와
  같이 정의
</p>
<p data-ke-size="size16">
  $$ \mathcal{M}(i^{\mathsf{view}_{j}}, k^{\mathsf{view}_{\ell}}) = \left\{
  \begin{array}{rcl} 1 &amp; \mbox{for} &amp; (i, j \in \mathbf{H}) \\ |
  \mathbf{Q}_{i, k} - \mathsf{Norm} ( S(i^{\mathsf{view}_{j}},
  k^{\mathsf{view}_{\ell}}) ) | &amp; \mbox{for} &amp; (i, j \in \mathbf{H})
  \tag{2} \end{array}\right. $$
</p>
<p data-ke-size="size16">
  &bull; 최종 손실은 서로 다른 뷰 상 동일한 샘플에 대하여
  \(\mathcal{M}(i^{\mathsf{view}_{j}}, k^{\mathsf{view}_{\ell}})\) 함수와
  \(S(i^{\mathsf{view}_{j}}, k^{\mathsf{view}_{\ell}})\) 함수 값이 커지는
  방향으로 식 (3)과 같이 설계
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathcal{L} (i^{\mathsf{view}_{j}}) \varpropto - \log [
  \mathcal{M}(i^{\mathsf{view}_{j}}, k^{\mathsf{view}_{\ell}}) \cdot
  S(i^{\mathsf{view}_{j}}, k^{\mathsf{view}_{\ell}}) ] \tag{3} \end{equation} $$
</p>
<hr
  contenteditable="false"
  data-ke-type="horizontalRule"
  data-ke-style="style5"
/>
<p data-ke-size="size18">
  <b>6. Attribute and Structure Preserving Graph Contrastive Learning</b>
</p>
<p data-ke-size="size16"><i>[24.03.11]</i></p>
<p data-ke-size="size16">
  &bull; original view, attribute view, global structure view를 각각 생성하고,
  이로부터 얻은 4개의 representations에 대한 교차 대조 학습으로 생성한 3개의
  loss로 모델을 훈련시킴. 코드 있음
</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><i>[24.03.24]</i></p>
<p data-ke-size="size16">
  &bull; 식 (1)과 같이 정규화된 인접 행렬을 이용하여 정점 간 메시지 전파.
  \(\tilde{A}\)는 self-loops가 추가된 인접 행렬. \(D\)는 \(A\)의 차수 행렬. 식
  (2-1)에서 \(\ell &gt; P \). 식 (2-2)에서 heterophilous graph일 경우
  \(\mathbf{S}_{F}\)를 이용
</p>
<p data-ke-size="size16">
  &bull; 정점 \(i\)는 각각의 표현에 대하여 본인 정점만을 양성 샘플로 취급. 식
  (3)과 같이 세 가지 손실들을 가중합하여 최종 손실을 계산
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathbf{S} = \tilde{\mathbf{D}}^{-1/2} \tilde{\mathbf{A}}
  \tilde{\mathbf{D}}^{-1/2}, \ \ \mathbf{S}_{F} = \mathbf{D}^{-1/2} \mathbf{A}
  \mathbf{D}^{-1/2} \tag{1} \end{equation} $$
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathbf{H}^{o} = \mathbf{S}^{P} \mathbf{X}
  \mathbf{\Theta}_{a}, \ \ \mathbf{H}^{s} = (\mathbf{S}_{G})^{\ell} \mathbf{X}
  \mathbf{\Theta}_{s} \ \ (\mathbf{S}_{G} \in \{\mathbf{S}, \mathbf{S}_{F}\})
  \tag{2-1} \end{equation} $$
</p>
<p data-ke-size="size16">
  $$ \begin{equation} \mathbf{H}^{\tilde{o}} = \mathbf{S}^{P} \mathbf{X}
  \mathbf{\Theta}_{\tilde{o}}, \ \ \mathbf{H}^{a} = \mathbf{S}^{P} \mathbf{X}
  \mathbf{\Theta}_{a} + \mathbf{S}_{F} \mathbf{X} \mathbf{\Theta}_{a} \tag{2-2}
  \end{equation} $$
</p>
<p data-ke-size="size16">
  $$ \mathcal{L}_{\mathsf{attr}} + \lambda_{1} \mathcal{L}_{\mathsf{str}} +
  \lambda_{2} \mathcal{L}_{\mathsf{cross}} = \left\{ \begin{array}{rcl}
  \mathcal{L}_{\mathsf{attr}}(v_{i}) \varpropto -\mathsf{sim} (h_{i}^{o},
  h_{i}^{a}) \\ \mathcal{L}_{\mathsf{str}}(v_{i}) \varpropto -\mathsf{sim}
  (h_{i}^{\tilde{o}}, h_{i}^{s}) \\ \mathcal{L}_{\mathsf{cross}}(v_{i})
  \varpropto -\mathsf{sim} (h_{i}^{o}, h_{i}^{\tilde{o}}) \tag{3}
  \end{array}\right. $$
</p>
<hr
  contenteditable="false"
  data-ke-type="horizontalRule"
  data-ke-style="style5"
/>
