<p data-ke-size="size16">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</p>

<p data-ke-size="size18"><b>2024_0413</b></p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<p data-ke-size="size16">
  &bull; Sag-DRE 확인 결과, 성능이 오히려 소폭 상승함. 조금 돌아가더라도 Wei의 의도를 명확히 해야 할 필요가 있음. 일전에 NLP 교수님께서도 그래프 트랜스포머를 언급해주셨던 기억이 있음. 이 방안도
  참고해보겠음
</p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>저자의 의도 다시 정리하기</b></p>

<p data-ke-size="size16">
  &bull; 저자(Wei, Li)는 두 가지 문제를 지적함. (1) DRE를 위한 GNN들이 <u>sequential 정보</u>를 명확히 포착하지 못하고 있음. (2) 손실 함수를 설계할 때 multi-labels의 long-tail 이슈를 고려하지 못하고
  있음. 문제 (1)을 해결하기 위해 sentence-level과 document-level, token-level의 <u>sequential 정보</u>를 각각 문장 그래프에 대한 GCN, 문장 그래프의 루트 노드 간의 어텐션, k-shortest paths에 대한
  LSTM과 어텐션으로 학습함. 문제 (2)를 해결하기 위해 separation class를 이용한 adaptive margin loss를 설계함
</p>

<p>&nbsp;</p>

<p data-ke-size="size16">&bull; 하지만 실험적으로 GCN 대신 MLP를 이용하더라도 sentence-level에서 추출하는 정보에는 손실이 없었음</p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>빠르게 논문 네 편 훑어보기</b></p>

<p data-ke-size="size16">
  &bull; <i>Document-level relation extraction via graph transformer networks and temporal convolutional networks</i>는 21년 ELSEVIER에 게재된 논문. 하지만 코드는 없음. 해당 논문의 저자들 역시 DRE를
  다루고 있고 sentence-level RE와 비교할 때 DRE의 성능을 결정짓는 주요 요인이
  <u>여러 문장 속 어딘 가에 흩뿌려져 있는 엔티티 간의 관계를 포착하기 위한 문장 사이의 관계 정보를 명확히 학습하는 것</u>으로 지목함. 저자들은 <u>TCN</u>을 이용해 문서 내 문장들로부터 그래프를
  생성하고 <u>GTN</u>을 이용해 문장 간 관계 정보를 학습함
</p>

<p data-ke-size="size16">
  &bull; <i>Graph Trnasformer Networks</i>는 고려대학교의 저자들이 NIPS 2019에서 발표한 논문. heterogeneous 그래프를 학습하는 전통적인 방법은 meta-paths를 이용해 homogeneous 그래프로 변환하여 그래프
  신경망을 이용하는 것. 저자들의 GTN이 각광받는 주된 이유는 meta-paths를 end-to-end 방식으로 생성하는 최초의 모델이었기 때문이라고 생각함
</p>

<p data-ke-size="size16">
  &bull; <i>Document-level Relation Extraction as Semantic Segmentation</i>은 21년에 게재된 논문으로 일부 저자들이 알리바바에 속해 있는 것으로 봐서는 신뢰할 수 있을 것 같음. 이 논문의 저자들은 DRE를
  수행하기 위해 CV의 기술을 변형하였음. 기존의 graph, transformer 기반의 방식을 이용하지 않았다는 점에서 많은 사람들에게 인용된 것 같음
</p>

<p data-ke-size="size16">
  &bull; <i>Heterogeneous Graph Transformer</i>는 2020년 IW3C2라는 학회에 게재되었음. 저자들이 UCLA와 마이크로소프트에 소속되어 있기 때문에 신뢰도 상승. 저자들은 기존의 heterogeneous 그래프를 학습하는
  연구들이 Web 스케일에 적합하지 않음을 지적함
</p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>어텐션 제거</b></p>

<p data-ke-size="size16">
  &bull; Sag-DRE 저자들이 어텐션을 이용해서 문장 간의 관계를 학습하였다면 <u>어텐션을 제거하는 것</u>이 성능에 더 크게 기여할 것으로 예상됨. 저자들이 이야기한 GCN 레이어의 제거가 어텐션을 포함한
  것일까 의문스러움. 만약 맞다면 DRE에서의 핵심은 문장 내 메시지 패싱이 아닌 문장 간 메시지 패싱이 됨. JobID는 11078815
</p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>BiVE의 방법을 이용하면 GCN과 Attn을 상위 레벨에서 한 번에 프로세싱할 수 있을까?</b></p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>DocRED: A Large-Scale Document-Level Relation Extraction Dataset (Yao, Yuan, et al)</b></p>

<p data-ke-size="size16">
  &bull; 저자는 DocRED의 <i>Kungliga Hovkapellet</i> 문서를 예시로 들며, 이 문서에 존재하는 19개의 관계 인스턴스 중 2개의 관계 인스턴스만을 보이고 있음. 저자는 <i>part_of</i>와 <i>country</i> 관계에
  해당되는 엔티티들만 파란색으로 표기하고 나머지 엔티티들은 밑줄을 그어 표시하였음. 저자는 <i>Riddarhuset</i>과 <i>Sweden</i> 엔티티 사이의 <i>country</i>라는 관계를 식별하기 위해 4번 문장에서
  <i>Riddarhuset</i>이 <i>Stockholm</i>에 위치해 있음을 식별해야 하며 1번 문장에서 <i>Stockholm</i>이 <i>Sweden</i>의 수도임을 식별해야 하는 것처럼 문장과 문장을 넘나드는 추론이 필요하다고 설명함
</p>

<p data-ke-size="size16">&bull; Sag-DRE의 저자들은 Human-annotated DocRED 데이터셋을 사용했음. 이게 더 작음</p>

<p>&nbsp;</p>

<p>[##_Image|kage@6UMwz/btsGBwcY8XN/N6CkMkGfswZKYJvXtgCERK/img.png|CDM|1.3|{"originWidth":640,"originHeight":579,"style":"alignCenter","caption":"그림 1"}_##]</p>

<p>&nbsp;</p>

<p data-ke-size="size16">
  &bull; DocRED <u>데이터셋 이해하기</u>. 지금 시점에서 이 행위가 논문을 쓰는데에는 직접적으로 도움이 안됨. 그렇다고 다른 논문들을 읽는 것은 밑 빠진 독에 물 붓기. 논문을 못 쓰더라도 DocRED 데이터셋에
  대한 이해는 남길 거리가 있음. 추가로 라이브러리 기록과 에러 기록도 남길 거리가 됨
</p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
