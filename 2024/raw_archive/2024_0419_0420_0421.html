<p data-ke-size="size16">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</p>

<style>
  code {
    font-family: "Pretendard-Regular";
    font-size: inherit;
    color: rgb(255, 101, 101);
    background: rgb(236, 230, 223);
    word-wrap: break-word;
    box-decoration-break: clone;
    padding: 0.1rem 0.3rem 0.2rem;
    border-radius: 0.2rem;
  }
</style>

<p data-ke-size="size18"><b>2024_0419</b></p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<p data-ke-size="size16"><b>잡생각</b></p>

<p data-ke-size="size16">&bull; <u>주 1회 저자 인터뷰하기</u>. 다음 주부터 시작. GACL에 대해 표면만 보았던 과거의 기록과 달리 저자의 의도를 고민하고 기록하기 시작한 점을 보며 성장했음을 느낌</p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>미팅 기록</b></p>

<p data-ke-size="size16">
  &bull; (1) GACL의 차원에 따른 인공 그래프의 recall 성능 확인하기. (2) recall이 향상된 그래프를 이용하여 대조 학습 하였을 때 정점 분류 성능이 향상되는지 확인하기. 앞선 두 가지가 보장된 이후에
  end-to-end로 모델을 설계하는 것이 성공 확률을 높여줌. 충분한 가설 검증 없이 바로 실험에 뛰어들면 시간 낭비
</p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<p data-ke-size="size18"><b>2024_0420</b></p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<p data-ke-size="size16"><b>잡생각</b></p>

<p data-ke-size="size16">
  &bull; 명상: 생각 조각 모음. 14시 35분. 칼디책 저자와 함께 데이터셋 전처리를 공부하기 위해 도커 사용법을 정리함. 그리고 데이터셋 다운 받고 내 이미지 파일 하나 만들어두려고 하는데 꽤 긴 시간 멈춰
  있음. 그래서 잠시 딴짓을 할까 고민하고 있음. 10분만에 복귀. 16시 22분. 저자가 입출력 양식에 대한 이야기를 시작하며 집중력이 뚝 떨어짐. 파이토치-칼디 프로젝트와 스피치브레인의 존재를 알게됨. 변경이
  가능하다면 바꾸고 싶음. 무엇보다 코랩으로 가능. 17시 22분. 더 찾는 것은 의미가 없기 때문에 <u>분류</u>와 <u>평가</u>가 필요함. 시작은 <u>파이토치-칼디</u>와 <u>스피치브레인</u>의 존재를 알게 된 것.
  Wave2vec이 유명해보였고 이것 역시 파이토치로 구현되어 있었음. 칼디의 필요성에 의문을 제기. 저자들이 예시로 든 LibriSpeech 데이터셋은 음성 데이터셋 중 가장 유명한 것 중 하나로 보임. 이 데이터셋에
  대한 사용량 중에 허깅페이스와 토치가 매우 많은 비중을 차지하고 있었음. 그렇다면 이를 이용한 연구가 현재 활발하다는 것을 짐작할 수 있음. 음성 인식, 화자 인식 분야의 오픈 소스 점유율을 확인하고자
  하였으나 실패했음. LibriSpeech 사전 학습 모델을 허깅페이스에서 사용할 수 있다는 점도 확인하였음. 하지만 불확실한 한 가지는 발표를 듣는 청자인 교수님과 다른 학생들에게 만족될만한 정보를 제공할 수
  있는지임. 결정함. 저자의 의도 중 일부인 <u>LibriSpeech 데이터셋으로 모델을 학습하기 위한 전처리 과정</u>에 대해서 파이썬 버전으로 발표하도록 하겠음
</p>

<p data-ke-size="size16">
  &bull; 출근 아홉 시간 만에 다시 해야 함을 알게 된 이 뭣같은 기분. 청자들은 모두 음성 인식 분야에서 나보다 전문가들임. 따라서 도움을 줄 수 있는 방향은 그래프 데이터적인 관점을 덧붙이는 것 외에는
  없음. 왜냐하면 토치로 정리해봤자 알고 있는 정보를 정리하는 것 뿐이기 때문
</p>

<p data-ke-size="size16">
  &bull; 내 발표를 듣는 청자들이 아니라 내 글을 읽을 독자들에 더 높은 가중치를 둔다면 트랜스포머를 활용한 음성 데이터 학습 모델 설계 과정을 기술하는 것이 더 가치 있음. 뿐만 아니라 나한테도 더 쓸모가
  있음. 그렇다면 앞서 생각했듯이 내가 발표해야 하는 부분에 담긴 저자의 의도 중 데이터에 대한 전처리 과정을 담되 좀 더 큰 그림에서 청자들에게 이야기를 전달할 수 있도록 하겠음. 이를 통해 청자들도 음성
  데이터를 전공하지 않는 이 학생이 음성 데이터에 대한 처리 기술을 익혔다는 느낌을 줄 수 있도록 하겠음. 교수님의 입장에서 생각해봐도 단순히 칼디를 다루는 경험이 아니라 내가 음성 데이터에 흥미를 갖고
  숙련도를 쌓는 것이 더 원하는 바일 것 같음
</p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>예상 독자가 아예 비전공자일 때 내가 한 설명</b></p>

<p data-ke-size="size16">
  &bull; 코딩하기 = 프로그램 만들기. 프로그램이란 컴퓨터를 동작시키는 명령어들의 모음. 나 같은 데이터 과학자들이 하는 일은 학습 모델을 만드는 것. 모델은 데이터를 바탕으로 공부하는 프로그램. 잘 학습한
  모델은 문제를 잘 맞출 수 있음. 이때 데이터의 종류가 매우 다양하고 데이터에 따라 모델을 다르게 설계해야 함. 그래서 데이터별로 모델 엔지니어들이 다양함. 자연어처리 수업 → 텍스트 데이터. 음성인식 수업
  → 음성 데이터. 내 연구 → 그래프 데이터. 어쨌든 내가 발표해야 하는 건 음성 데이터를 모델이 학습할 수 있게 가공하는 과정
</p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<p data-ke-size="size18"><b>2024_0421</b></p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<p data-ke-size="size16">&bull; 평가의 주체인 음성인식, 자연어처리, 정보이론 교수님을 중심에 두고 생각하기</p>

<p data-ke-size="size16">&bull; 10시 45분. 이발하고 물세수까지 완료. 19시. 1년 목표 오랜만에 수정. 목표 수준의 성장을 체감. 물론 발표 준비는 0%. 22시 0%</p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
