<p data-ke-size="size16">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</p>

<style>
  code {
    font-family: "Pretendard-Regular";
    font-size: inherit;
    color: rgb(255, 101, 101);
    background: rgb(236, 230, 223);
    word-wrap: break-word;
    box-decoration-break: clone;
    padding: 0.1rem 0.3rem 0.2rem;
    border-radius: 0.2rem;
  }
</style>

<p data-ke-size="size18"><b>Libraries</b></p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<h2 data-ke-size="size26"><b>PyTorch</b></h2>

<p data-ke-size="size16"><b>unsqueeze</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
import torch

x = torch.tensor([[1,2,3,4], [5,6,7,8]])
print(x.shape)
print(torch.unsqueeze(x, 0).shape)
print(torch.unsqueeze(x, 1).shape)
print(torch.unsqueeze(x, 2).shape)
print(torch.unsqueeze(x, -1).shape)

"""
torch.Size([2, 4])
torch.Size([1, 2, 4])
torch.Size([2, 1, 4])
torch.Size([2, 4, 1])
torch.Size([2, 4, 1])
"""
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style1" />

<p data-ke-size="size16"><b>cat</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
import torch

a = torch.rand(5,4)
b = torch.rand(5,4)
c = torch.cat([a,b], dim=0)
e = torch.cat([a,b], dim=1)
f = torch.cat([a,b], dim=-1)

print(c.shape, e.shape, f.shape)

"""
torch.Size([10, 4]) 
torch.Size([5, 8]) 
torch.Size([5, 8])
"""
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style1" />

<p data-ke-size="size16"><b>gather</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
import torch

x = torch.tensor([[1, 2], [3, 4]])
print(f"텐서 x: {x}")

index = torch.tensor([[0, 0], [1, 0]])
y0 = torch.gather(x, 0, index)
y1 = torch.gather(x, 1, index)

print(f"텐서 y0: {y0}")
print(f"텐서 y1: {y1}")

"""
텐서 x: tensor([[1, 2],
                [3, 4]])
텐서 y0: tensor([[1, 2],
                [3, 2]])
텐서 y1: tensor([[1, 1],
                [4, 3]])
"""
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style1" />

<p data-ke-size="size16"><b>cuda</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
import torch

x = torch.rand(3,2)
y = x.cuda()
z = x.to("cuda:0")

print(x)
print(y)
print(z)

"""
tensor([[0.4677, 0.7961],
        [0.5107, 0.2023],
        [0.8831, 0.7336]])
tensor([[0.4677, 0.7961],
        [0.5107, 0.2023],
        [0.8831, 0.7336]], device='cuda:0')
tensor([[0.4677, 0.7961],
        [0.5107, 0.2023],
        [0.8831, 0.7336]], device='cuda:0')
"""
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style1" />

<p data-ke-size="size16"><b>index_select</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
import torch

x = torch.randn(3, 4)

indices = torch.tensor([0, 2])
y = torch.index_select(x, 0, indices)
z = torch.index_select(x, 1, indices)

print(x)
print('#' * 60)
print(y)
print('-' * 60)
print(z)

"""
tensor([[-1.4170,  1.5288,  1.1879, -1.9599],
        [-0.0386,  1.1006,  1.1733, -0.4420],
        [-2.0631,  0.0671, -0.5285,  0.3361]])
############################################################
tensor([[-1.4170,  1.5288,  1.1879, -1.9599],
        [-2.0631,  0.0671, -0.5285,  0.3361]])
------------------------------------------------------------
tensor([[-1.4170,  1.1879],
        [-0.0386,  1.1733],
        [-2.0631, -0.5285]])
"""
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style1" />

<p data-ke-size="size16"><b>Linear</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
import torch.nn as nn

layer = nn.Linear(128, 128)

X = torch.rand(16, 128)
Y = torch.rand(128, 16)

Z = layer(X)
# Z = layer(Y)  # RuntimeError
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style1" />

<p data-ke-size="size16"><b>IterableDataset</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>
# class BERTDGLREDataset(IterableDataset)

train_set = BERTDGLREDataset(train_set_path, ner2id, rel2id)

print(f"샘플 개수: {len(train_set)}")
print(f"data 딕셔너리: {train_set.data[0].keys()}")
print(f"ner2id 딕셔너리: {train_set.ner2id.keys()}")
print(f"rel2id 딕셔너리: {train_set.rel2id.keys()}") # 97

""" 
샘플 개수: 3,053
data 딕셔너리: dict_keys(['vertexSet', 'labels', 'title', 'sents'])
ner2id 딕셔너리: dict_keys(['BLANK', 'ORG', 'LOC', 'TIME', 'PER', 'MISC', 'NUM'])
rel2id 딕셔너리: dict_keys(['P1376', 'P607', 'P136', ..., 'P1056'])

{'vertexSet': [[{'pos': [0, 4], 'type': 'ORG', ... }}
{'vertexSet': [[{'pos': [7, 9], 'type': 'MISC', ...}}
"""
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style1" />

<p data-ke-size="size16"><b>DataLoader</b></p>

<p data-ke-size="size16">&bull; CPU로 동작시키기 위해 모든 <code>cuda</code> 제거</p>

<p>&nbsp;</p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>
# class BERTDGLREDataLoader(DataLoader)

train_loader = DGLREDataloader(train_set, 
                                batch_size=16, 
                                shuffle=True, 
                                negativa_alpha=4)

"""
3,053개의 샘플을 16개의 배치 단위로 구분하여 총 191개의 배치를 생성함
"""

batch_size = 1
batch_num = 0
for x in train_loader:
    if batch_num == batch_size:
        break
    one_batch = x
    batch_num += 1

one_batch.keys()

"""
dict_keys(['context_idxs', 'context_pos', 'context_ner', 'context_word_mask', 'context_word_length', 'h_t_pairs', 
           'relation_label', 'relation_multi_label', 'relation_mask', 'relation_example_idx', 'labels', 'graph2s', 
           'sub2words', 'word2sents', 'path2_table', 'L_vertex', 'titles', 'indexes'])
"""
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<h2 data-ke-size="size26"><b>Transformer</b></h2>

<p data-ke-size="size16"><b>BertTokenizer</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
from transformers import BertTokenizer

my_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')

text = 'hello world'
tokens = my_tokenizer.tokenize(text)
token_ids = my_tokenizer.convert_tokens_to_ids(tokens)

"""
tokens: ['hello', 'world']
token_ids: [19082, 1362]
"""

# BertTokenizer를 이용하여 정의한 Bert 클래스

class Bert():
  MASK = '[MASK]'
  CLS = "[CLS]"
  SEP = "[SEP]"

  def __init__(self):
    super().__init__()
    self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')
  
# ... 

my_bert = Bert()

words = words[:10]
print(f"words 개수: {len(words)}, words 구성: {words}")

subwords, token_starts_ids = my_bert.subword_tokenize(words)
print(f"subwords 개수: {len(subwords)}, subwords 구성: {subwords}")

"""
words 개수: 10
words 구성: ['The', 'short', '-', 'beaked', 'common', 'dolphin', '(', 'Delphinus', 'delphis', ')']

subwords 개수: 18
subwords 구성: ['[CLS]', 'The', 'short', '-', 'be', '##aked', 'common', 'do', '##lphin', '(', 'Del', '##phi', '##nus', 'del', '##phi', '##s', ')', '[SEP]']
"""
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<h2 data-ke-size="size26"><b>Spacy</b></h2>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
nlp = spacy.load('en_core_web_lg')
print(len(nlp.vocab.vectors))
print(len(nlp.vocab.vectors[2667587279770775948]))

"""
514157  # 514K
300     # dimension
"""
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<h2 data-ke-size="size26"><b>Scikit-learn</b></h2>

<p data-ke-size="size16"><b>T-SNE</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
# import torch
# import numpy as np
# from torch_geometric.datasets import Planetoid
# from sklearn.manifold import TSNE
# from matplotlib import pyplot as plt 

dataset_name = 'cora'
path = '/.../data'

dataset = Planetoid(path, dataset_name)
data = dataset[0]

features = data.x
feat_numpy = features.numpy()

labels = data.y.numpy()

reduced_emb = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(feat_numpy)

unique_labels = data.y.unique().numpy()
for label in unique_labels:
    idx = np.where(labels == label)
    plt.scatter(reduced_emb[idx, 0], reduced_emb[idx, 1], marker='.', label=label)

plt.legend()
plt.show()
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<h2 data-ke-size="size26"><b>DGL</b></h2>

<p data-ke-size="size16"><b>DGLGraph</b></p>

<pre id="code_1712975682143" class="python" data-ke-language="python" data-ke-type="codeblock"><code>      
# import dgl

print(g.edges()[0].shape) == print(g.edges()[1].shape)
print(g.number_of_nodes())

"""
True
number_of_nodes
"""

</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<!-- added -->
