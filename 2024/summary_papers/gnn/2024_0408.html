<p data-ke-size="size16">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</p>
<p data-ke-size="size18"><b>그래프 데이터에 대한 심층학습 성능 향상을 위한 여섯 편의 논문 비교 분석</b></p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<!-- 처음 -->
<p data-ke-size="size16">이 글의 목적은 여섯 편의 논문을 정형화된 형태로 기록함으로써 우연성과 무의식의 작업 효율을 조금이라도 높이기 위함이다.</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16">&nbsp;</p>
<!-- 중간 -->
<p data-ke-size="size16">여섯 편의 논문의 본질적인 공통점은 <u>그래프 데이터에 대한 심층학습 성능 향상</u>이며 이에 대한 각 연구의 핵심 아이디어를 아래와 같이 요약하였다.</p>
<p data-ke-size="size16">&bull; (1) ALT는 주어진 그래프 데이터를 주파수 영역 신호 관점에서 분석하고 레이블 정보를 이용하여, 동질성 및 이질성에 무관하게, 적응적으로 필터를 조정하였다.</p>
<p data-ke-size="size16">
  &bull; (2) GACL은 HTG에 대한 기존의 대조학습이 모두 동질성 가정에 전제하고 있음을 지적하며, 정점 간 유사성을 높이는 기존의 방법이 아닌 이웃한 정점의 고유 신호에 대한 예측 정확도를 높이는 방법을
  제안하였다.
</p>
<p data-ke-size="size16">
  &bull; (3) DGCN은 특징 뷰를 생성하기 위해 주어진 그래프로부터 인공 HMG와 HTG를 레이블 정보 없이 생성하였고 이를 바탕으로 적응적인 필터를 설계하였다. 특징 뷰와 구조 뷰를 분리하기 위해 추가로 구조
  뷰를 생성하였다.
</p>
<p data-ke-size="size16">
  &bull; (4) MUSE는 Heterophilous Graph에서 관찰된 각 정점과 그들의 이웃 정점들 간의 상이한 유사도 분포를 시작점으로, 정점의 고유 벡터와 이웃 정보들을 종합한 벡터를 분리하여 학습한 뒤 혼합하였다.
</p>
<p data-ke-size="size16">&bull; (5) HSAN은 동질성 가정을 전제로 하며 샘플의 가치(harndess)를 훈련 과정 중 동적으로 고려함으로써 대조학습에 쓰일 샘플의 품질을 높였다.</p>
<p data-ke-size="size16">
  &bull; (6) NCLA는 기존 GCL의 그래프 증강 전략과 대조 전략이 그래프 도메인에 적합하지 않음을 지적하였다. 이를 해결하기 위해 멀티-해드 그래프 증강 네트워크와 동질성 가정을 고려한 그래프 대조 전략을
  제안하였다.
</p>
<p data-ke-size="size16">&nbsp;</p>

<p data-ke-size="size16">두 모델씩 뽑아 차이점을 기록하였고 별도의 선정 기준을 고려하진 않았다. 먼저 <u>HSAN과 MUSE의 세 가지 차이점</u>을 아래와 같이 분석하였다.</p>
<p data-ke-size="size16">
  &bull; (1) HSAN은 서로 다른 네 개의 다층 퍼셉트론 인코더를 이용하여 네 개의 뷰를 생성하고, MUSE는 하나의 그래프 신경망 인코더를 이용하여 두 개의 뷰를 생성하고 두 뷰를 결합하여 세 번째 뷰를
  생성하였다.
</p>
<p data-ke-size="size16">
  &bull; (2) HSAN은 라플라시안 필터를 특징 행렬에 적용한 뒤 특징 뷰를 생성하는, 파라미터를 공유하지 않는, 두 개의 인코더에 각각 주입하였다. 반면 MUSE는 HTG를 집중적으로 다루기 때문에 정점의 고유(ego)
  벡터와 이웃 정점들로부터 정보를 종합한(aggregated) 벡터를 분류하였다.
</p>
<p data-ke-size="size16">
  &bull; (3) HSAN은 샘플의 가치를 동적으로 고려하며 특징 뷰와 구조 뷰를 대조하는 반면, MUSE는 각각의 뷰에 대한 랜덤 분포 뷰를 대조의 대상으로 삼아 각 뷰의 일관성을 향상시켰다.
</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><u>ALT와 DGCN의 세 가지 차이점</u>을 아래와 같이 분석하였다.</p>
<p data-ke-size="size16">&bull; (1) ALT는 레이블 정보를 이용하여 필터가 적응적으로 조정되도록 설계하였고, DGCN은 인공적으로 생성한 HMG와 HTG의 라플라시안 행렬을 모두 고려한 필터를 설계하였다.</p>
<p data-ke-size="size16">&bull; (2) ALT는 특징 행렬과 구조 행렬을 분리하지 않고 하나의 벡터 공간에 사상한 점에 반해, DGCN은 두 공간을 명시적으로 분리하였다.</p>
<p data-ke-size="size16">
  &bull; (3) 단순히 크로스 엔트로피 손실을 사용하는 ALT와 달리 DGCN은 각 뷰 간의 상관관계에 관련된 손실과 불필요한 샘플들의 가중치를 낮추는 손실, 상대 엔트로피를 고려한 손실을 종합적으로 이용하였다.
</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><u>GACL과 NCLA의 두 가지 차이점</u>은 아래와 같이 분석하였다.</p>
<p data-ke-size="size16">
  &bull; (1) 두 모델 모두 기존 그래프 대조학습에서 이용하였던 그래프 증강 방법에 문제가 있었다는 점을 지적하였다. 단 GACL은 그래프를 증강하지 않는 방법을 취했고 NCLA는 멀티-해드 어텐션 네트워크를
  이용하여 \(K\)개의 그래프를 증강하는 방법을 취했다.
</p>
<p data-ke-size="size16">
  &bull; (2) NCLA는 동질성 가정(homophily assumption)을 적극 이용하여 서로 다른 뷰 상에서 양성 샘플의 범위를 이웃 정점들까지 확장한 것에 반해, GACL은 이웃 정점의 고유 벡터를 예측하는 전략을 연결되어
  있는 정점 간의 벡터가 비대칭성을 갖도록, 평탄(smoothness)해지지 않도록, 설계하였다.
</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16">&nbsp;</p>
<!-- 끝 -->
<p data-ke-size="size16">긴 시간을 투자한 고민에 대해 결과물을 남길 수 있었다는 점에서 만족하였다.</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<p data-ke-size="size16">&bull; 2,062자</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
