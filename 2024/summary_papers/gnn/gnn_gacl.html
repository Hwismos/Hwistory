<p data-ke-size="size16">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</p>
<p data-ke-size="size18">
  <b>Simple and Asymmetric Graph Contrastive Learning without Augmentations</b>
</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size16"><i>[24.03.13]</i></p>
<p data-ke-size="size16">
  &bull; HTG의 정점들은 (1) 동일한 클래스에 속한 정점에 대하여 유사한 1-hop 구조(context)를 갖고, (2) 2-hop 거리의 이웃 정점과는 유사한
  특징(semantic)을 갖는 성질(monophily)이 있음. 따라서 한 정점에 대한 표현에, 1-hop 정점들과의 구조 정보와 2-hop 정점들의 특징 정보가 담길 수 있도록
  인코더를 설계함
</p>
<p data-ke-size="size16">
  &bull; \(g_{\phi}\)는 정점 \(v\)의 표현(\(\mathbf{v}\))으로부터 \(v\)의 이웃 정점인 \(u\)의 표현(\(\mathbf{u}\))을 복원하는 예측기(projection).
  예측기가 항등 함수(identity function)가 되는 것을 방지하기 위해 \(\mathbf{v}\)와 \(\mathbf{u}\)에 각각의 인코더(\(f_{\theta}\), \(f_{\xi}\))를 적용.
  단 파라미터 \(\xi\)는 \(\theta\)에 기반하여 간접적으로 갱신됨. 정점 표현의 차별성을 더욱 보장하기 위해 \(f_\theta\)를 이용해 생성한 k개의 랜덤한
  음성 샘플의 표현(\(\mathbf{v}\_\))과 \(v\)의 표현(\(\mathbf{v}\))의 거리가 최대가 되도록 규제(regularization)함
</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size16"><i>[24.03.14]</i></p>
<p data-ke-size="size16">&bull; \(f_{\theta}\)는 graphconv[1, 2]로 \(f_{\xi}\)는 requires_grad를 False로 설정한 target_graphconv[1, 2]로 구현</p>
<p data-ke-size="size16">&nbsp;</p>
<p data-ke-size="size16"><i>[24.03.21]</i></p>
<p data-ke-size="size16">
  &bull; 정점 \(v\)로부터 표현 \(\mathbf{v}\)(v_emb)와 \(\mathbf{p}\)(projected_emb)를 생성. \(v\)의 이웃 정점인 \(u\)로부터 \(\mathbf{u}\)(u_emb)를
  생성. \(\mathbf{p}\)와 \(\mathbf{u}\)가 유사해지고, \(\mathbf{v}\)와 \(v\)의 음성 샘플(\(v\_\))의 표현인 \(\mathbf{v\_}\)가 달라지도록 손실 함수를
  설계함
</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size16"><i>[24.03.26]</i></p>
<p data-ke-size="size16">
  &bull; 한 정점으로 세 가지 표현 벡터(\(\mathbf{v}, \mathbf{u}, \mathbf{p}\))를 생성. \(\mathbf{v}\) 벡터를 본인을 포함한 모든 벡터들과 달리 지도록
  강제함. 이를 통해 oversmoothing 예방. 이웃한 정점들에 대한 \(\mathbf{u}\) 벡터를 \(\mathbf{p}\) 벡터와 유사해지도록 강제함으로써 한 이웃 정점을
  공유하는 임의의 두 정점의 \(\mathbf{p}\) 벡터가 비슷해지도록 만듦. 각 클래스에 속하는 정점들의 1-hop 패턴이 유사하다면 동일한 클래스에 속하는
  정점들의 \(\mathbf{p}\) 벡터 역시 유사한 방향으로 학습됨
</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size16"><i>[24.04.01]</i></p>
<p data-ke-size="size16">
  &bull; 인트로의 두 가지 핵심 내용. (1) 이웃 정점들을 양성 샘플로 취급하고 이웃하지 않은 정점들을 음성 샘플로 취급하여 대조 학습을 수행하던 방법은
  동질성 가정을 전제로 함. (2) 각각의 증강된 뷰 상에서 동일한 정점만을 양성 샘플로 취급하고 나머지 정점들은 음성 샘플로 취급하여 대조 학습을 수행하던
  방법 역시 암묵적으로 동질성에 의존함. 따라서 (1)과 (2) 모두 heterophilous 그래프에 부적합함
</p>
<p data-ke-size="size16">
  &bull; CCGC의 \(\tilde{\mathbf{x}}\) 벡터는 주변 이웃 벡터들의 병합된 정보를 갖고 있음. GACL의 \(\mathbf{p}\) 벡터는 1-hop contextual 정보와 2-hop
  monophily 정보를 갖고 있음. 더 유용한 \(\mathbf{p}\) 벡터를 unshared 샴 인코더에 주입하고 클러스터링을 수행한다면 homophilous 그래프 뿐 아니라
  heterophilous 그래프에 대한 클러스터링도 가능함. 단 GREET과 같이 각각의 모듈이 별개로 동작해야 함. 또한 CCGC 모듈로 인해 GACL 모듈에서 얻은 정보가
  손실될 수도 있기 때문에 적절한 규제가 필요할 수 있음 (반대 상황도 가능)
</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size16"><i>[24.04.06]</i></p>
<p data-ke-size="size16">
  &bull; <u>평탄화 연산</u>에 의존하였던 기존 대조학습들과 달리 GACL은 비대칭적인 설계(predictor)를 이용해 중심 정점의 표현 벡터가 이웃한 정점들의
  <u>고유 신호</u>(original signal, context)를 <u>예측</u>할 수 있도록 하였음
</p>
<p>&nbsp;</p>
<p>[##_Image|kage@kLQQy/btsGp2crypI/QcGgrofeB7SPnugkUi7flK/img.png|CDM|1.3|{"originWidth":2206,"originHeight":474,"style":"alignCenter"}_##]</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
<p data-ke-size="size16"><i>[24.04.11]</i></p>
<p data-ke-size="size16">
  &bull; 저자는 비대칭적 예측 레이어로 1-hop context와 2-hop monophily를 학습할 수 있도록 함으로써 heterophilous graph에 적합한 대조 학습 알고리즘을
  설계함. 추가로 정점 벡터의 붕괴(constant) 방지를 위한 다양성을 보장해주는 손실을 설계함
</p>
<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
