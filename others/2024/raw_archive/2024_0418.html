<p data-ke-size="size16">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</p>

<style>
  code {
    font-family: "Pretendard-Regular";
    font-size: inherit;
    color: rgb(255, 101, 101);
    background: rgb(236, 230, 223);
    word-wrap: break-word;
    box-decoration-break: clone;
    padding: 0.1rem 0.3rem 0.2rem;
    border-radius: 0.2rem;
  }
</style>

<p data-ke-size="size18"><b>2024_0418</b></p>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />

<p data-ke-size="size16"><b>정보이론 수업</b></p>

<p data-ke-size="size16">
  &bull;
  <a title="황원석 교수님 페이지" href="https://uos-nlp.notion.site/607086cab1d64fb1acdcd0b940a6d6f8?v=76815c0ac0e64d4095ac7e93f8511d6f" target="_blank" rel="noopener"
    >https://uos-nlp.notion.site/607086cab1d64fb1acdcd0b940a6d6f8?v=76815c0ac0e64d4095ac7e93f8511d6f</a
  >
</p>

<p data-ke-size="size16">&bull; 교수님과의 소통. 혼합 가우시안 모델의 최대 우도 추정을 이용한 클러스터링 알고리즘 분석</p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>잡생각</b></p>

<p data-ke-size="size16">
  &bull; 데이터 과학자 관련 논문 구현하기에 대한 태훈님의 생각. 정답만이 제시된 소스 코드를 보는 것에 끝내지 말고 그 속에 녹아 있던 저자의 실패 과정과 그 과정 속에 담긴 저자의 의도를 파악할 것
</p>

<p data-ke-size="size16">
  &bull; 계획을 세워보겠음. 오늘 15시부터는 당장 직면한 문제에서 잠시 거리를 두고 M과 함께 저자와의 소통을 수행할 것임. 트레이시는 <u>고객과의 소통</u>을 핵심으로 꼽음.
  <u>주 1회 1편의 논문 및 코드 읽기</u>를 통해 저자 뿐 아니라 컴퓨터와의 소통 능력도 향상 시키도록 하겠음. 작년에 교수님이 주신 논문 리스트 참고. 지금 나름 저자와 소통이 된 것이라 해봤자 GREET과
  SagDRE, GACL 정도가 전부. 막무가내로 많이 읽는 행위는 불필요. 오늘 M과의 미팅 중 핵심 과제는 <u>상호 간의 공감 수준을 허용범위 안으로 일치시키는 것</u>. 그리고 나는 GACL 저자와의 소통을 통해 내일
  교수님과의 논의를 준비할 것
</p>

<p data-ke-size="size16">
  &bull; 국내 heterophilous graph contrastive learning 분야에서는 최고가 되겠음. 초등학교 때 과학상자를 가지고 시간 가는 줄 모르고 놀았던 기억이 있음. 딱 지금 과학상자가 데이터로 바뀐 느낌
</p>

<p data-ke-size="size16">
  &bull; 17시 40분. 2시간 정도 간 진행된 M과의 미팅 종료. 이번이 세 번째 미팅. 다음 미팅 때까지의 준비물은 <u>코드와 논문에 담긴 저자의 의도를 정리한 글</u>과 <u>같이 소통하며 공부하려는 마음가짐</u>.
  글은 블로그에 올려두겠음. path 관련 벡터를 제거한 뒤 성능의 하락 정도도 확인해야 함. 그래야 그래프 구조 개선의 영향력을 확인할 수 있음
</p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>GACL 저자(Xiao)와 소통하기</b></p>

<p data-ke-size="size16">
  &bull; 저자가 의도한 GNNModel 훈련 방법을 따라가기 위해 <code>g</code> 객체 준비 중. 노드에 요청하여 데이터셋을 다운 받은 뒤 데이터셋의 <code>pt</code> 파일을 클라이언트에 저장하여 ipynb에서 로드.
  클라이언트에서는 <code>URLError</code>가 발생하기 때문
</p>

<p data-ke-size="size16">
  &bull; 의도적으로 그래프 객체 <code>g</code>를 cuda 메모리에 저장해보았음. 쿠다 메모리 할당량이 증가하였으나 이를 줄이는 방법을 찾진 못함. <code>del g</code>로도 안 되었음. 커널 재시작하니 쿠다
  메모리가 초기화됨
</p>

<p data-ke-size="size16">
  &bull; 저자의 기저에 깔린 의도를 파악하기 위해 레이어 수준의 설계로 내려감. forward의 결과 당연히 <code>projected_emb</code>를 사용하는 줄 알았으나 <code>v_emb</code>를 반환하고 있음.
  <code>projected_emb</code>도 <code>v_emb</code>에 기인한 것이므로 예상 못할 정도는 아님. <code>sampled_embeddings</code>는 <code>u_emb</code> 기준으로 추출하고 <code>sampled_neg_embeddings</code>는
  <code>v_emb</code> 기준으로 추출. 저자의 논리가 명확해서인지 코드 자체도 상당히 깔끔하게 작성된 것 같음.
  <u>기존 그래프 대조 학습이 homophily assumption에 의존적이었다면 monophily에 의존적으로 그래프를 증강하는 것은 어떰</u>
</p>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>Libraries에 추가</b></p>

<pre id="code_1713341796812" class="python" data-ke-language="python" data-ke-type="codeblock"><code>
# stack
# 벡터 리스트를 행렬로 변환해줌

tensors = []

for _ in range(5):
    tensors.append(torch.rand(5))

torch.stack(tensors).shape  # torch.size([5, 5])
</code></pre>

<p>&nbsp;</p>

<p data-ke-size="size16"><b>GREET 저자와의 소통 기록</b></p>

<p data-ke-size="size16">
  &bull; M과의 미팅 이후 재개. chameleon 기준으로 structural encoding은 (2277, 16)임. Liu와 소통하기 위해 역시 모델 수준이 아닌 레이어 수준으로 내려가보겠음. 간선 판별기를 다르게 학습시킬 수는
  없을까?. 저자와의 소통 기록을 블로그에 기록해두겠음. 저자들은 간선 판별기의 성능을 향상시키기 위해 랜덤하게 뽑은 정점 쌍 간의 유사도와 간선이 존재하는 정점 쌍 간의 유사도가 달라지도록 손실 함수를
  설계하였음. 내가 생각하는 바는 피벗 기반의 손실 함수가 무의마하다는 점임. 초반과 큰 차이가 없는 것으로 기억함
</p>

<p data-ke-size="size16">
  &bull; 어떤 조정도 없이 feats와 se만을 이용해서 chameleon의 간선 판별 성능을 평가. 진짜 homophily 중 homophily를 맞추는 recall이 중요. 2.66% 나옴. 아예 못 맞추는거임. 절반이라고만 해도 50%는 맞음
</p>

<p data-ke-size="size16">
  &bull; 밥 먹고 다시 진행. monophily에 기반해서 간선 판별기를 학습 시키는 방법이 있을까 고민 중. 하지만 GREET의 간선 판별기가 형편 없다라는 전제가 필요한데 그게 원복이 잘 안되고 있어서 고생 중
</p>

<p data-ke-size="size16">
  &bull; 36,101개의 간선 중 self_loops를 제거해서 36,051개의 간선을 이용. 36,051개의 간선을 가지고 생성한 인공 그래프에서 가중치가 0이 아닌 간선의 개수가 38,328개로 증가함. 간선의 가중치를 이용해서
  인공 그래프를 생성할 때 <code>torch.eye()</code> 함수를 이용해서 self_loops를 추가하기 때문인 것으로 확인함
</p>

<p>&nbsp;</p>

<pre id="code_1713341796812" class="python" data-ke-language="python" data-ke-type="codeblock"><code>
print_confusion_matrix_result(res_1)
print_confusion_matrix_result(res_200)
print_confusion_matrix_result(res_500)

'''
TP: 278
FP: 1
TN: 27616
FN: 10433

ACC:  72.78 || Precision:  99.64 || Recall:  2.60
##################################################
TP: 257
FP: 12
TN: 27605
FN: 10454

ACC:  72.69 || Precision:  95.54 || Recall:  2.40
##################################################
TP: 228
FP: 5
TN: 27612
FN: 10483

ACC:  72.64 || Precision:  97.85 || Recall:  2.13
##################################################
'''
</code></pre>

<p>&nbsp;</p>

<p data-ke-size="size16">&bull; 위 결과에서 볼 수 있듯이 간선 판별기는 전혀 학습되지 않았음. 초기 상태와 confusion matrix가 거의 바뀌지 않았음</p>

<p data-ke-size="size16">&bull; 레이어에 안 넣고 v_emb로 인공 그래프를 만든다면? recall 성능이 열 배 가량 늘었음</p>

<p>&nbsp;</p>

<pre id="code_1713341796812" class="python" data-ke-language="python" data-ke-type="codeblock"><code>
print_confusion_matrix_result(res_by_v_emb)
  
'''
TP: 2277
FP: 0
TN: 27617
FN: 8434

ACC:  78.00 || Precision:  100.00 || Recall:  21.26
##################################################
'''
</code></pre>

<hr contenteditable="false" data-ke-type="horizontalRule" data-ke-style="style5" />
